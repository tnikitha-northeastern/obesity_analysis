diabetes_training_data <- diabetes_data[index,]
diabetes_test_data <- diabetes_data[-index,]
model_predicted_accuracy <- data.frame(pred_model = character(),accuracy = numeric(), cutpoint = numeric())
nn.model <- neuralnet(Outcome~Pregnancies + Glucose + BloodPressure +
SkinThickness + Insulin + BMI + DiabetesPedigreeFunction +
Age, data=diabetes_training_data,hidden=c(3),stepmax = 1000000,
linear.output=FALSE)
library(neuralnet)
nn.model <- neuralnet(Outcome~Pregnancies + Glucose + BloodPressure +
SkinThickness + Insulin + BMI + DiabetesPedigreeFunction +
Age, data=diabetes_training_data,hidden=c(3),stepmax = 1000000,
linear.output=FALSE)
diabetes_test_data$output <- predict(nn.model,diabetes_test_data[,-9])
diabetes_test_data$prednn <- diabetes_test_data$output*(max(diabetes_data[-index,9])-min(diabetes_data[-index,9]))+min(diabetes_data[-index,9])
roc(diabetes_test_data$Outcome,diabetes_test_data$prednn,plot = TRUE,percent=TRUE,
xlab="False Positive Percentage", ylab="True Postive Percentage",
main = "Neural Network",
col="darkgreen", lwd=4,legacy.axes=TRUE,print.auc=TRUE)
for (i in 1:9) {
cutpoint <- i/10
diabetes_test_data$pred <- case_when (diabetes_test_data$prednn > i/10 ~ 'diabetes predicted',
diabetes_test_data$prednn <= i/10  ~ 'diabetes not predicted')
t <- table(diabetes_test_data$Outcome,diabetes_test_data$pred)
accuracy = (t[1,1] + t[2,2])/(t[1,1] + t[2,2] + t[2,1]+t[1,2])
mod <- "neural network"
vec <- c(mod,accuracy,cutpoint)
df[i, ] <- vec
print(df)
print(df)
par(pty = "s")
roc(diabetes_test_data$Outcome,diabetes_test_data$prednn,plot = TRUE,percent=TRUE,
xlab="False Positive Percentage", ylab="True Postive Percentage",
main = "Multiple Models",
col="darkgreen", lwd=4,legacy.axes=TRUE,print.auc=TRUE)
plot.roc(diabetes_test_data$Outcome,diabetes_test_data$predglm,percent = TRUE,
col ="steelblue3",lwd = 4,print.auc=TRUE,add = TRUE,print.auc.y=40)
legend("bottomright", legend=c("Neural Network", "Logistic Regression"),
col = c("darkgreen", "steelblue3"), lwd=4)
plot.roc(diabetes_test_data$Outcome,diabetes_test_data$predglm,percent = TRUE,
col ="steelblue3",lwd = 4,print.auc=TRUE,add = TRUE,print.auc.y=40)
legend("bottomright", legend=c("Neural Network", "Logistic Regression"),
col = c("darkgreen", "steelblue3"), lwd=4)
par(pty = "s")
roc(diabetes_test_data$Outcome,diabetes_test_data$prednn,plot = TRUE,percent=TRUE,
xlab="False Positive Percentage", ylab="True Postive Percentage",
main = "Multiple Models",
col="darkgreen", lwd=4,legacy.axes=TRUE,print.auc=TRUE)
library(pROC)
par(pty = "s")
roc(diabetes_test_data$Outcome,diabetes_test_data$prednn,plot = TRUE,percent=TRUE,
xlab="False Positive Percentage", ylab="True Postive Percentage",
main = "Multiple Models",
col="darkgreen", lwd=4,legacy.axes=TRUE,print.auc=TRUE)
plot.roc(diabetes_test_data$Outcome,diabetes_test_data$predglm,percent = TRUE,
col ="steelblue3",lwd = 4,print.auc=TRUE,add = TRUE,print.auc.y=40)
plot.roc(diabetes_test_data$Outcome,diabetes_test_data$predglm,percent = TRUE,
col ="steelblue3",lwd = 4,print.auc=TRUE,add = TRUE,print.auc.y=40)
library(rpart)
library(rpart.plot)
library(pROC)
library(dplyr)
diabetes_data <-read.csv("/Users/nikithathota/downloads/diabetes_2-1 (1).csv")
set.seed(42)
# --- make sure Outcome is a factor with levels "0","1" so rpart does classification
diabetes_training_data$Outcome <- factor(diabetes_training_data$Outcome, levels = c(0,1))
diabetes_test_data$Outcome     <- factor(diabetes_test_data$Outcome,     levels = c(0,1))
dt_model <- rpart(
Outcome ~ .,
data   = diabetes_training_data,
method = "class"  # classification tree
# control = rpart.control(cp = 0.01) # optional tuning
)
rpart.plot(dt_model)
dt_prob <- predict(dt_model, newdata = diabetes_test_data, type = "prob")[, "1"]
diabetes_test_data$preddt <- dt_prob
roc_dt <- roc(response = diabetes_test_data$Outcome,
predictor = diabetes_test_data$preddt,
levels = c("0","1"), direction = "<",
plot = TRUE, percent = TRUE,
xlab="False Positive Percentage", ylab="True Positive Percentage",
main = "Decision Tree (rpart) — ROC",
col="steelblue3", lwd=4, legacy.axes=TRUE, print.auc=TRUE)
model_predicted_accuracy <- data.frame(
pred_model = character(),
accuracy   = numeric(),
cutpoint   = numeric(),
stringsAsFactors = FALSE
)
for (i in 1:9) {
cutpoint <- i/10
pred_cls <- ifelse(diabetes_test_data$preddt > cutpoint, "1", "0")
# confusion matrix with factor levels aligned
cm <- table(truth = diabetes_test_data$Outcome,
pred  = factor(pred_cls, levels = c("0","1")))
acc <- (cm["0","0"] + cm["1","1"]) / sum(cm)
model_predicted_accuracy[i, ] <- c("Decision Tree", acc, cutpoint)
}
print(model_predicted_accuracy)
library(randomForest)
library(pROC)
diabetes_data <-read.csv("/Users/nikithathota/downloads/diabetes_2-1 (1).csv")
set.seed(42)
diabetes_training_data$Outcome <- factor(diabetes_training_data$Outcome, levels = c(0,1))
diabetes_test_data$Outcome     <- factor(diabetes_test_data$Outcome,     levels = c(0,1))
rf_model <- randomForest(
Outcome ~ .,
data = diabetes_training_data,
ntree = 500,           # common default; increase for stability
mtry  = floor(sqrt(ncol(diabetes_training_data)-1)),  # typical heuristic
importance = TRUE,
proximity = FALSE
)
rf_prob <- predict(rf_model, newdata = diabetes_test_data, type = "prob")[, "1"]
diabetes_test_data$predrf <- rf_prob
roc_rf <- roc(
response  = diabetes_test_data$Outcome,
predictor = diabetes_test_data$predrf,
levels = c("0","1"), direction = "<",
plot = TRUE, percent = TRUE,
xlab = "False Positive Percentage", ylab = "True Positive Percentage",
main = "Random Forest — ROC",
col = "red", lwd = 4, legacy.axes = TRUE, print.auc = TRUE
)
model_predicted_accuracy <- data.frame(
pred_model = character(), accuracy = numeric(), cutpoint = numeric(),
stringsAsFactors = FALSE
)
for (i in 1:9) {
cutpoint <- i/10
pred_cls <- ifelse(diabetes_test_data$predrf > cutpoint, "1", "0")
cm <- table(
truth = diabetes_test_data$Outcome,
pred  = factor(pred_cls, levels = c("0","1"))
)
acc <- (cm["0","0"] + cm["1","1"]) / sum(cm)
model_predicted_accuracy[i, ] <- c("Random Forest", acc, cutpoint)
}
print(model_predicted_accuracy)
library(e1071)
library(pROC)
diabetes_data <-read.csv("/Users/nikithathota/downloads/diabetes_2-1 (1).csv")
set.seed(42)
diabetes_training_data$Outcome <- factor(diabetes_training_data$Outcome, levels = c(0,1))
diabetes_test_data$Outcome     <- factor(diabetes_test_data$Outcome,     levels = c(0,1))
svm_model <- svm(
Outcome ~ .,
data = diabetes_training_data,
kernel = "radial",       # "linear", "polynomial", or "sigmoid" are options
probability = TRUE,      # <-- required to later get calibrated probs
scale = TRUE             # e1071 scales features by default; keep TRUE even if you've normalized
)
svm_raw <- predict(svm_model, newdata = diabetes_test_data, probability = TRUE)
svm_prob <- attr(svm_raw, "probabilities")[, "1"]    # column named by positive class label
diabetes_test_data$predsvm <- svm_prob
roc_svm <- roc(
response  = diabetes_test_data$Outcome,
predictor = diabetes_test_data$predsvm,
levels = c("0","1"), direction = "<",
plot = TRUE, percent = TRUE,
xlab = "False Positive Percentage", ylab = "True Positive Percentage",
main = "SVM — ROC",
col = "green", lwd = 4, legacy.axes = TRUE, print.auc = TRUE
)
model_predicted_accuracy <- data.frame(
pred_model = character(), accuracy = numeric(), cutpoint = numeric(),
stringsAsFactors = FALSE
)
for (i in 1:9) {
cutpoint <- i/10
pred_cls <- ifelse(diabetes_test_data$predsvm > cutpoint, "1", "0")
cm <- table(
truth = diabetes_test_data$Outcome,
pred  = factor(pred_cls, levels = c("0","1"))
)
acc <- (cm["0","0"] + cm["1","1"]) / sum(cm)
model_predicted_accuracy[i, ] <- c("SVM", acc, cutpoint)
}
print(model_predicted_accuracy)
library(pROC)
diabetes_data <-read.csv("/Users/nikithathota/downloads/diabetes_2-1 (1).csv")
diabetes_test_data$Outcome <- factor(diabetes_test_data$Outcome, levels = c("0","1"))
# If you've already created these columns, skip this block.
# Expected columns holding probabilities for class "1":
#   - Decision Tree: diabetes_test_data$preddt
#   - Random Forest: diabetes_test_data$predrf
#   - SVM          : diabetes_test_data$predsvm
stopifnot(all(c("preddt","predrf","predsvm") %in% names(diabetes_test_data)))
roc_dt  <- roc(diabetes_test_data$Outcome, diabetes_test_data$preddt,  levels=c("0","1"), direction="<")
- roc(diabetes_test_data$Outcome, diabetes_test_data$predrf,  levels=c("0","1"), direction="<")
roc_dt  <- roc(diabetes_test_data$Outcome, diabetes_test_data$preddt,  levels=c("0","1"), direction="<")
roc_rf  <- roc(diabetes_test_data$Outcome, diabetes_test_data$predrf,  levels=c("0","1"), direction="<")
roc_svm <- roc(diabetes_test_data$Outcome, diabetes_test_data$predsvm, levels=c("0","1"), direction="<")
plot.roc(roc_dt,
percent = TRUE, legacy.axes = TRUE,
col = "#1b9e77", lwd = 3,
xlab = "False Positive Percentage", ylab = "True Positive Percentage",
main = "ROC Comparison: Decision Tree vs Random Forest vs SVM",
print.auc = FALSE)
lines.roc(roc_rf,  col = "#d95f02", lwd = 3)
lines.roc(roc_svm, col = "#7570b3", lwd = 3)
abline(a = 0, b = 1, lty = 3)
plot.roc(roc_dt,
percent = TRUE, legacy.axes = TRUE,
col = "#1b9e77", lwd = 3,
xlab = "False Positive Percentage", ylab = "True Positive Percentage",
main = "ROC Comparison: Decision Tree vs Random Forest vs SVM",
print.auc = FALSE)
lines.roc(roc_rf,  col = "#d95f02", lwd = 3)
lines.roc(roc_svm, col = "#7570b3", lwd = 3)
auc_dt  <- as.numeric(auc(roc_dt))  * 100
auc_rf  <- as.numeric(auc(roc_rf))  * 100
auc_svm <- as.numeric(auc(roc_svm)) * 100
legend("bottomright",
legend = c(
sprintf("Decision Tree  (AUC = %.2f%%)", auc_dt),
sprintf("Random Forest  (AUC = %.2f%%)", auc_rf),
sprintf("SVM            (AUC = %.2f%%)", auc_svm)
),
col = c("#1b9e77","#d95f02","#7570b3"),
lwd = 3, bty = "n")
print(model_predicted_accuracy)
library(pROC)
diabetes_data <-read.csv("/Users/nikithathota/downloads/diabetes_2-1 (1).csv")
# Ensure binary factor with positive class "1"
diabetes_test_data$Outcome <- factor(diabetes_test_data$Outcome, levels = c("0","1"))
# If you've already created these columns, skip this block.
# Expected columns holding probabilities for class "1":
#   - Decision Tree: diabetes_test_data$preddt
#   - Random Forest: diabetes_test_data$predrf
#   - SVM          : diabetes_test_data$predsvm
stopifnot(all(c("preddt","predrf","predsvm") %in% names(diabetes_test_data)))
# Build ROC objects
roc_dt  <- roc(diabetes_test_data$Outcome, diabetes_test_data$preddt,  levels=c("0","1"), direction="<")
roc_rf  <- roc(diabetes_test_data$Outcome, diabetes_test_data$predrf,  levels=c("0","1"), direction="<")
roc_svm <- roc(diabetes_test_data$Outcome, diabetes_test_data$predsvm, levels=c("0","1"), direction="<")
# Plot first ROC, then add the others
plot.roc(roc_dt,
percent = TRUE, legacy.axes = TRUE,
col = "#1b9e77", lwd = 3,
xlab = "False Positive Percentage", ylab = "True Positive Percentage",
main = "ROC Comparison: Decision Tree vs Random Forest vs SVM",
print.auc = FALSE)
lines.roc(roc_rf,  col = "#d95f02", lwd = 3)
lines.roc(roc_svm, col = "#7570b3", lwd = 3)
abline(a = 0, b = 1, lty = 3)
# Legend with AUCs (convert to % for readability)
auc_dt  <- as.numeric(auc(roc_dt))  * 100
auc_rf  <- as.numeric(auc(roc_rf))  * 100
auc_svm <- as.numeric(auc(roc_svm)) * 100
legend("bottomright",
legend = c(
sprintf("Decision Tree  (AUC = %.2f%%)", auc_dt),
sprintf("Random Forest  (AUC = %.2f%%)", auc_rf),
sprintf("SVM            (AUC = %.2f%%)", auc_svm)
),
col = c("#1b9e77","#d95f02","#7570b3"),
lwd = 3, bty = "n")
library(tidyverse)
library(ggplot2)
library(reshape2)
library(corrplot)
path <- "/users/nikithathota/documents/New_Nutrition_Physical_Activity_Obesity_Clean.csv"  # adjust if needed
raw <- readr::read_csv(path) %>% clean_names()
setwd("~")
library(tidyverse)
library(ggplot2)
library(reshape2)
library(corrplot)
path <- "/users/nikithathota/documents/New_Nutrition_Physical_Activity_Obesity_Clean.csv"  # adjust if needed
path
raw <- readr::read_csv(path) %>% clean_names()
raw <- readr::read_csv(path)
head(raw)
df <- raw %>%
filter(class == "Obesity / Weight Status",
str_detect(question, regex("have obesity", ignore_case = TRUE)),
data_value_type == "Value",
!str_detect(age_years, regex("UNKNOWN", ignore_case = TRUE)),
year_start >= 2011, year_start <= 2023) %>%
select(year = year_start,
state = location_desc,
state_abbr = location_abbr,
value = data_value,
age = age_years,
sex = sex,
)
view(df)
df_by_age_year <- df %>%
group_by(age, year) %>%
summarise(value = mean(value, na.rm = TRUE), .groups = "drop") %>%
arrange(age, year)
df <- raw %>%
filter(class == "Obesity / Weight Status",
str_detect(question, regex("have obesity", ignore_case = TRUE)),
data_value_type == "Value",
!str_detect(age_years, regex("UNKNOWN", ignore_case = TRUE)),
year_start >= 2011, year_start <= 2023) %>%
select(year = year_start,
state = location_desc,
state_abbr = location_abbr,
value = data_value,
age = age_years,
sex = sex,
)
view(raw)
library(tidyverse)
library(ggplot2)
library(reshape2)
library(corrplot)
library(janitor)
path <- "/users/nikithathota/documents/New_Nutrition_Physical_Activity_Obesity_Clean.csv"  # adjust if needed
raw <- readr::read_csv(path) %>% clean_names()
df <- raw %>%
filter(class == "Obesity / Weight Status",
str_detect(question, regex("have obesity", ignore_case = TRUE)),
data_value_type == "Value",
!str_detect(age_years, regex("UNKNOWN", ignore_case = TRUE)),
year_start >= 2011, year_start <= 2023) %>%
select(year = year_start,
state = location_desc,
state_abbr = location_abbr,
value = data_value,
age = age_years,
sex = sex,
)
df_by_age_year <- df %>%
group_by(age, year) %>%
summarise(value = mean(value, na.rm = TRUE), .groups = "drop") %>%
arrange(age, year)
ggplot(df_by_age_year, aes(x = year, y = value, color = age, group = age)) +
geom_line(linewidth = 1) +
geom_point(size = 1.1) +
labs(title = "Mean Obesity prevalance Over the Years by Age Group",
x = "Year", y = "Mean Obesity Prevalence (%)", color = "Age Group") +
scale_x_continuous(breaks = scales::pretty_breaks()) +
theme_minimal(base_size = 12) +
theme(plot.title = element_text(hjust = 0.5))
pwd
setwd("~/Documents/GitHub/obesity_analysis")
ggplot(df, aes(x = age, y = value, fill = age)) +
geom_boxplot() +
labs(title = "Obesity prevalence by Age Group",
x = "Age Group",
y = "obesity Prevalence") +
theme_minimal() +
theme(plot.title = element_text(hjust = 0.5)) +
theme(legend.position = "none")
state_year <- df %>%
group_by(year, state, state_abbr) %>%
summarize(obesity_pct = mean(value, na.rm = TRUE), .groups = "drop")
state_order <- state_year %>%
filter(year == 2023) %>%
arrange(desc(obesity_pct)) %>%
pull(state)
state_year <- df %>%
group_by(year, state, state_abbr) %>%
summarize(obesity_pct = mean(value, na.rm = TRUE), .groups = "drop")
state_order <- state_year %>%
filter(year == 2023) %>%
arrange(desc(obesity_pct)) %>%
pull(state)
ggplot(state_year %>% mutate(state = factor(state, levels = state_order)),
aes(x = year, y = state, fill = obesity_pct)) +
geom_tile() +
scale_fill_viridis_c(name = "Mean Obesity Prevalence (%)", option = "C") +
labs(title = "Mean Obesity Prevalence by State and Year",
x = "Year", y = NULL) +
theme_minimal(base_size = 12)
northeast <- c("Maine","Vermont","New Hampshire","Massachusetts","Connecticut","Rhode Island",
"New York","New Jersey","Pennsylvania")
midwest   <- c("Ohio","Indiana","Illinois","Michigan","Wisconsin","Minnesota","Iowa","Missouri",
"North Dakota","South Dakota","Nebraska","Kansas")
south     <- c("Delaware","Maryland","District of Columbia","Virginia","West Virginia","Kentucky",
"North Carolina","South Carolina","Georgia","Florida","Alabama","Mississippi",
"Tennessee","Arkansas","Louisiana","Oklahoma","Texas")
west      <- c("Montana","Idaho","Wyoming","Colorado","New Mexico","Arizona","Utah","Nevada",
"Washington","Oregon","California","Alaska","Hawaii")
state_year <- state_year %>%
mutate(region = case_when(
state %in% northeast ~ "Northeast",
state %in% midwest   ~ "Midwest",
state %in% south     ~ "South",
state %in% west      ~ "West",
TRUE                 ~ NA_character_
))
state_year <- state_year %>% filter(!is.na(region))
regional_year <- state_year %>%
group_by(year, region) %>%
summarize(regional_pct = mean(obesity_pct, na.rm = TRUE), .groups = "drop")
ggplot(regional_year, aes(year, regional_pct, color = region)) +
geom_line(linewidth = 1.3) +
geom_point(size = 1.6) +
labs(title = "Regional Trends in Adult Obesity (2011–2023)",
x = "Year", y = "Mean obesity prevalence (%)", color = "Region") +
scale_y_continuous(labels = label_percent(scale = 1)) +
theme_minimal(base_size = 12)
library(scales)
library(dplyr)
ggplot(regional_year, aes(year, regional_pct, color = region)) +
geom_line(linewidth = 1.3) +
geom_point(size = 1.6) +
labs(title = "Regional Trends in Adult Obesity (2011–2023)",
x = "Year", y = "Mean obesity prevalence (%)", color = "Region") +
scale_y_continuous(labels = label_percent(scale = 1)) +
theme_minimal(base_size = 12)
low10_2023 <- state_year %>%
filter(year == 2023) %>%
slice_min(obesity_pct, n = 10) %>%
arrange(desc(obesity_pct)) %>%                           # order for a nice ascending bar chart
mutate(state = factor(state, levels = state))      # keep this order on the plot
top10_2023 <- state_year %>%
filter(year == 2023) %>%
slice_max(obesity_pct, n = 10) %>%
arrange(obesity_pct) %>%                           # order for a nice ascending bar chart
mutate(state = factor(state, levels = state))      # keep this order on the plot
ggplot(top10_2023, aes(x = state, y = obesity_pct, fill = obesity_pct)) +
geom_col() +
# geom_vline(xintercept = nat_avg_2023, linetype = "dashed", color = "red") +
coord_flip() +
scale_y_continuous(labels = label_percent(scale = 1)) +
scale_fill_gradient(
name = "Obesity Rate (%)",
low = "#A7C7E7",    # light blue for lower values
high = "#08306B"    # dark blue for higher values
) +
labs(title = "10 Most Obese States in 2023",
x = "US State",
y = "Obesity Rate (%)") +
theme_minimal(base_size = 13) +
theme(
plot.title = element_text(hjust = 0.5),
legend.position = "right"
)
ggplot(low10_2023, aes(x = state, y = obesity_pct, fill = obesity_pct)) +
geom_col() +
# geom_vline(xintercept = nat_avg_2023, linetype = "dashed", color = "red") +
coord_flip() +
scale_y_continuous(labels = label_percent(scale = 1)) +
scale_fill_gradient(
name = "Obesity Rate (%)",
low = "#A7C7E7",    # light blue for lower values
high = "#08306B"    # dark blue for higher values
) +
labs(title = "10 Least Obese States in 2023",
x = "US State",
y = "Obesity Rate (%)") +
theme_minimal(base_size = 13) +
theme(
plot.title = element_text(hjust = 0.5),
legend.position = "right"
)
anova_two_way <- aov(value ~ factor(year) * factor(age), data = df_subset)
df_subset <- df_by_age_year %>%
filter(year %in% c(2011, 2023))
anova_two_way <- aov(value ~ factor(year) * factor(age), data = df_subset)
summary(anova_two_way)
anova_two_way <- aov(value ~ factor(year) * factor(age), data = df_by_age_year)
summary(anova_two_way)
df_subset <- df_by_age_year %>% filter(year %in% c(2011, 2023))
anova_two_way <- aov(value ~ factor(year) * factor(age), data = df_subset)
summary(anova_two_way)
anova_two_way <- aov(value ~ factor(year) * factor(age), data = df_by_age_year)
summary(anova_two_way)
anova_regional <- aov(regional_pct ~ factor(region) * factor(year), data = regional_year) summary(anova_regional)
anova_regional <- aov(regional_pct ~ factor(region) * factor(year), data = regional_year)
summary(anova_regional)
anova_age <- aov(value ~ factor(age), data = df)
summary(anova_age)
library(tidyverse)
library(ggplot2)
library(reshape2)
library(corrplot)
library(randomForest)
library(rpart)
library(rpart.plot)
library(caret)
library(keras)
library(nnet)
path <- "/users/nikithathota/documents/Sleep_health_and_lifestyle_dataset_cleaned.csv"  # adjust if needed
raw <- readr::read_csv(path) %>% clean_names()
view(raw)
raw$bmi_category <- as.factor(raw$bmi_category)
set.seed(123)  # for reproducibility
index <- sample(1:nrow(raw), 0.8 * nrow(raw))
train <- raw[index, ]
test  <- raw[-index, ]
rf_model <- randomForest(bmi_category ~ sleep_duration + stress_level + physical_activity_level, data = train)
print(rf_model)
predictions <- predict(rf_model, test)
confusion <- table(test$bmi_category, predictions)
print(confusion)
accuracy <- mean(predictions == test$bmi_category)
cat("Test Accuracy:", round(accuracy * 100, 2), "%\n")
view(test$bmi_category)
view(test)
test %>% group_by(bmi_category)
test %>% count(bmi_category)
print(confusion)
accuracy <- mean(predictions == test$bmi_category)
cat("Test Accuracy:", round(accuracy * 100, 2), "%\n")
predictions == test$bmi_category
predictions
nrow(predictions)
nrows(predictions)
count(predictions)
n_rows(predictions)
nrow(predictions)
nrow(test)
nrow(test) # works for df
dim(predictions)
class(test)
class(predictions)
